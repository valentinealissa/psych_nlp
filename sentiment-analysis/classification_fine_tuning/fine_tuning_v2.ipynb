{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, \\\n",
    "    DataCollatorWithPadding, EarlyStoppingCallback\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "from pynvml import *\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used // 1024 ** 2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['sentence'], truncation=True, max_length=128)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    scmetrics.add_batch(predictions=predictions, references=labels)\n",
    "    return scmetrics.compute()\n",
    "\n",
    "\n",
    "def create_labels(sentiment):\n",
    "    labels = []\n",
    "    for s in sentiment:\n",
    "        if s == 'neutral':\n",
    "            labels += [0]\n",
    "        elif s == 'negative':\n",
    "            labels += [1]\n",
    "        else:\n",
    "            labels += [2]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'sentiment', 'label'],\n",
      "        num_rows: 88\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'sentiment', 'label'],\n",
      "        num_rows: 22\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/88 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description='Sentence classification task')\n",
    "# parser.add_argument('--model', help='Path to pt model and tokenizer')\n",
    "# config = parser.parse_args(sys.argv[1:])\n",
    "task = 'sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\" #minerva: download model from hugging face and put in folder, update to path\n",
    "\n",
    "# set seed\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create task Dataset from annotated samples\n",
    "sentences = pd.read_csv('sentiment_language.csv', header=0)\n",
    "sentences = sentences[['Language', \"Alissa's label\"]]\n",
    "dataset = Dataset.from_pandas(sentences).rename_columns({'Language': 'sentence', \"Alissa's label\": 'sentiment'})\n",
    "dataset = dataset.add_column('label', create_labels(dataset['sentiment']))\n",
    "label_dt = dataset.train_test_split(0.2)\n",
    "\n",
    "print(label_dt)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tkn_dt = label_dt.map(tokenize_function, batched=True, num_proc=4) # batched tokenizing activated\n",
    "# tkn_dt = tkn_dt.remove_columns(['']) # at some point we might need to delete sentiment column or else get an error\n",
    "\n",
    "# data loader = allows us to use a chunk of the data at a time while training (or else computer crashes)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # read the sentences and pad them to create equal length vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL, num_labels=3)\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda') # put the model on the gpu once, and then add a batch everytime when doing a training or evaluation loop\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'batch_size': 2, 'epochs': 2, 'learning_rate': 2e-05, 'warmup_ratio': 0, 'weight_decay': 0.01}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 01:00, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.566200</td>\n",
       "      <td>0.701039</td>\n",
       "      <td>0.849084</td>\n",
       "      <td>0.816774</td>\n",
       "      <td>0.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.620500</td>\n",
       "      <td>0.601459</td>\n",
       "      <td>0.849084</td>\n",
       "      <td>0.816774</td>\n",
       "      <td>0.884615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.59      0.65      0.62        26\n",
      "weighted avg       0.82      0.88      0.85        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.59      0.65      0.62        26\n",
      "weighted avg       0.82      0.88      0.85        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.59      0.65      0.62        26\n",
      "weighted avg       0.82      0.88      0.85        26\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Parameters: {'batch_size': 2, 'epochs': 2, 'learning_rate': 2e-05, 'warmup_ratio': 0, 'weight_decay': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 01:10, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.328300</td>\n",
       "      <td>0.808800</td>\n",
       "      <td>0.850962</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.219300</td>\n",
       "      <td>0.739572</td>\n",
       "      <td>0.829983</td>\n",
       "      <td>0.822382</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.94      0.94      0.94        17\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.57      0.65      0.61        26\n",
      "weighted avg       0.82      0.88      0.85        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.57      0.63      0.59        26\n",
      "weighted avg       0.82      0.85      0.83        26\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.94      0.94      0.94        17\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.88        26\n",
      "   macro avg       0.57      0.65      0.61        26\n",
      "weighted avg       0.82      0.88      0.85        26\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Parameters: {'batch_size': 2, 'epochs': 2, 'learning_rate': 2e-05, 'warmup_ratio': 0.1, 'weight_decay': 0.01}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 01:07, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.165400</td>\n",
       "      <td>1.032144</td>\n",
       "      <td>0.828205</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>0.948628</td>\n",
       "      <td>0.829983</td>\n",
       "      <td>0.822382</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.59      0.63      0.61        26\n",
      "weighted avg       0.81      0.85      0.83        26\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.57      0.63      0.59        26\n",
      "weighted avg       0.82      0.85      0.83        26\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.57      0.63      0.59        26\n",
      "weighted avg       0.82      0.85      0.83        26\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Parameters: {'batch_size': 2, 'epochs': 2, 'learning_rate': 2e-05, 'warmup_ratio': 0.1, 'weight_decay': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 01:12, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>1.378657</td>\n",
       "      <td>0.828205</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>1.119966</td>\n",
       "      <td>0.824009</td>\n",
       "      <td>0.841346</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.59      0.63      0.61        26\n",
      "weighted avg       0.81      0.85      0.83        26\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.88      0.82      0.85        17\n",
      "           2       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.62      0.61      0.62        26\n",
      "weighted avg       0.84      0.81      0.82        26\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.59      0.63      0.61        26\n",
      "weighted avg       0.81      0.85      0.83        26\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best parameters configuration: {'batch_size': 2, 'epochs': 2, 'learning_rate': 2e-05, 'warmup_ratio': 0, 'weight_decay': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.59      0.63      0.61        26\n",
      "weighted avg       0.81      0.85      0.83        26\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.85        26\n",
      "   macro avg       0.59      0.63      0.61        26\n",
      "weighted avg       0.81      0.85      0.83        26\n",
      "\n",
      "{'test_loss': 1.3786574602127075, 'test_f1': 0.8282051282051281, 'test_precision': 0.8125, 'test_recall': 0.8461538461538461, 'test_runtime': 2.1223, 'test_samples_per_second': 12.251, 'test_steps_per_second': 6.125}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters (for best configuration selection)\n",
    "# 1st evaluate the hyper parameters once at a time, and select each hyper parameter that gives you the best score on results aka F1 vs recall\n",
    "params = {\n",
    "    'batch_size': [2], # [2, 4, 8],\n",
    "    'epochs': [2], # [1, 2, 5],\n",
    "    'learning_rate': [2e-5], # [5e-6, 1e-5, 2e-5, 5e-5, 1e-4],\n",
    "    'weight_decay': [0.01, 0.1], # [0, 0.01, 0.1], # how much the weight change is shrinking\n",
    "    'warmup_ratio': [0, 0.1], # [0, 0.01, 0.1] # ratio of examples it takes to get ready for the learning rate\n",
    "}\n",
    "\n",
    "metrics_file = f'classification_metrics_1run.csv'\n",
    "if os.path.isfile(metrics_file):\n",
    "    f = open(metrics_file, 'a')\n",
    "else:\n",
    "    f = open(metrics_file, 'w')\n",
    "    f.write('batch_size,epochs,learning_rate,weight_decay,warmup_ratio,loss,f1,precision,recall\\n')\n",
    "\n",
    "best_model = []\n",
    "# best_precision = 0.0\n",
    "best_f1 = 0.0\n",
    "tmp_trainer, tmp_comb = None, None\n",
    "for comb in list(ParameterGrid(params)):\n",
    "    print(f\"Parameters: {comb}\")\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'runs',\n",
    "        evaluation_strategy='epoch', # every epoch the model is evaluated and checkpoint is made saving the weights\n",
    "        eval_steps=1, # check, probably each step is by epoch\n",
    "        logging_strategy='epoch',\n",
    "        weight_decay=comb['weight_decay'],\n",
    "        warmup_ratio=comb['warmup_ratio'],\n",
    "        num_train_epochs=comb['epochs'],\n",
    "        learning_rate=comb['learning_rate'],\n",
    "        per_device_train_batch_size=comb['batch_size'],\n",
    "        per_device_eval_batch_size=comb['batch_size'],\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='eval_f1',\n",
    "        seed=42)\n",
    "    scmetrics = evaluate.load(\"scmetrics\")\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                      args=training_args,\n",
    "                      callbacks=[EarlyStoppingCallback(early_stopping_patience=10)], # if loss isnt decreasing for 2 epochs then it stops training\n",
    "                      train_dataset=tkn_dt['train'],\n",
    "                      eval_dataset=tkn_dt['test'],\n",
    "                      compute_metrics=compute_metrics,\n",
    "                      data_collator=data_collator)\n",
    "    results = trainer.train()\n",
    "    results_eval = trainer.evaluate()\n",
    "\n",
    "    v = [comb['batch_size'], comb['epochs'], comb['learning_rate'], comb['weight_decay'], comb['warmup_ratio'],\n",
    "    results.metrics['train_loss'], results_eval['eval_f1'], results_eval['eval_precision'], results_eval['eval_recall']]\n",
    "    f.write(','.join([str(el) for el in v]) + '\\n')\n",
    "\n",
    "    if results_eval['eval_f1'] > best_f1:\n",
    "        best_f1 = results_eval['eval_f1']\n",
    "        tmp_trainer = trainer\n",
    "        tmp_comb = comb\n",
    "    print('-' * 100)\n",
    "    print('\\n\\n')\n",
    "\n",
    "# Error analysis step\n",
    "labels_to_sen = {0: 'neutral', 1: 'negative', 2: 'positive'}\n",
    "if tmp_trainer is not None:\n",
    "    best_trainer = tmp_trainer\n",
    "    best_comb = tmp_comb\n",
    "    print(f'Best parameters configuration: {best_comb}')\n",
    "    dev_pred = best_trainer.predict(tkn_dt['test'])\n",
    "    pred = np.argmax(dev_pred.predictions, axis=-1)\n",
    "    pred_score = np.max(torch.nn.functional.softmax(torch.tensor(dev_pred.predictions), dim=-1).numpy(), axis=-1)\n",
    "    i = 0\n",
    "    errors = {'FP': [], 'FN': []}\n",
    "    for pred_lab, true_lab in zip(pred, dev_pred.label_ids):\n",
    "        if pred_lab != true_lab:\n",
    "            if pred_lab > 1:\n",
    "                errors['FP'].append((\n",
    "                    tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(tkn_dt['test']['input_ids'][i])),\n",
    "                    pred_score[i], labels_to_sen[pred_lab], labels_to_sen[true_lab]))\n",
    "            else:\n",
    "                errors['FN'].append((tokenizer.convert_tokens_to_string(\n",
    "                    tokenizer.convert_ids_to_tokens(tkn_dt['test']['input_ids'][i])), pred_score[i],\n",
    "                                     labels_to_sen[pred_lab], labels_to_sen[true_lab]))\n",
    "        i += 1\n",
    "    with open(f'error_analysis_v2.tsv',\n",
    "              'w') as f:\n",
    "        f.write('sentence\\tpredicted_label\\ttrue_label\\tprobability\\n')\n",
    "        for k, vect in errors.items():\n",
    "            if k == 'FP':\n",
    "                for sen in vect:\n",
    "                    f.write(sen[0] + '\\t' + f'PRED_{sen[2].upper()}' + '\\t' + f'TRUE_{sen[3].upper()}' + '\\t' + str(\n",
    "                        sen[1]) + '\\n')\n",
    "                f.write('\\n')\n",
    "            else:\n",
    "                for sen in vect:\n",
    "                    f.write(sen[0] + '\\t' + f'PRED_{sen[2].upper()}' + '\\t' + f'TRUE_{sen[3].upper()}' + '\\t' + str(\n",
    "                        sen[1]) + '\\n')\n",
    "    test_pred = best_trainer.predict(tkn_dt['test'])\n",
    "    print(test_pred.metrics)\n",
    "\n",
    "    model_dir = f'runs'\n",
    "    for d in os.listdir(model_dir):\n",
    "        # This removes the checkpoints (comment it if you want to keep them)\n",
    "        if 'checkpoint' in d:\n",
    "            shutil.rmtree(os.path.join(model_dir, d))\n",
    "    best_trainer.save_model(\n",
    "        output_dir=f'best_model')\n",
    "else:\n",
    "    print(\"Precision is 0.0 change something in your model's configuration and retry.\")\n",
    "f.close()\n",
    "\n",
    "#calculate F1 score for each group of labeled sentences i.e. 0 vs 1 vs 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Words                                           Language  \\\n",
      "0        Adamant  When told that her urine was positive for coca...   \n",
      "1    Cooperative  Pt was calm and cooperated with nursing care o...   \n",
      "2      Compliant  She says that the patient has been compliant w...   \n",
      "3       Agitated  states he was always quite sweet, not agitated...   \n",
      "4       Agitated  However, information from previous shift is th...   \n",
      "..           ...                                                ...   \n",
      "123          NaN  She has not been taking iron because it makes ...   \n",
      "124          NaN  She is a song writer and also sings. She has a...   \n",
      "125          NaN  She enjoys walking with her fiance and her dog...   \n",
      "126          NaN  He does not want to add a medication so I will...   \n",
      "127          NaN  She stated that even if it was positive, she w...   \n",
      "\n",
      "        Note ID        MRN Alissa's label    label     score  \n",
      "0    67625917.0  1796281.0       negative  LABEL_1  0.904331  \n",
      "1    57757871.0  6268061.0       positive  LABEL_2  0.999892  \n",
      "2    72475561.0  7176588.0        neutral  LABEL_1  0.999960  \n",
      "3    93800149.0  7066571.0       positive  LABEL_2  0.999408  \n",
      "4    89671764.0  2973674.0       negative  LABEL_1  0.999970  \n",
      "..          ...        ...            ...      ...       ...  \n",
      "123         NaN        NaN       positive  LABEL_2  0.999831  \n",
      "124         NaN        NaN       positive  LABEL_2  0.999823  \n",
      "125         NaN        NaN       positive  LABEL_2  0.999825  \n",
      "126         NaN        NaN       positive  LABEL_2  0.999856  \n",
      "127         NaN        NaN       positive  LABEL_2  0.999881  \n",
      "\n",
      "[128 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_task = pipeline(\"sentiment-analysis\",\n",
    "                          model = AutoModelForSequenceClassification.from_pretrained(\"best_model\", num_labels=3),\n",
    "                          tokenizer = AutoTokenizer.from_pretrained(MODEL))\n",
    "\n",
    "df = pd.read_csv('sentiment_language.csv')\n",
    "data = list(df['Language'].astype(str))\n",
    "sentiment_results = sentiment_task(data)\n",
    "df_results = pd.DataFrame(sentiment_results)\n",
    "final = pd.concat([df, df_results], axis = 1)\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('sentiment_results_park.csv', encoding = 'utf-8-sig') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "note1 = \"ED Psych Progress Note  Received sign out from day ED team. Pt with h/o bipolar disorder was BIB GM after pt repeatedly tried to run away from home, has not been compliant with treatment and has decompensated psychiatrically..  Has appeared oddly related with pressured speech and delusional thought content.  Tonight pt repeatedly asked to be seen, said she really thinks that she is pregnant and believes that she is ovulating, asking for pre-natal vitamin.  She continues to have pressured speech and at times talked about suing multiple people, and said she has proved to the supreme court that she is not psychiatrically ill.  She is fidgety but does not have any psychomotor agitation currently.    Pt is in need of admission but no adolescent bed available tonight.  Will continue to observe pt in ED and admit vs transfer in AM pending bed availability.\"\n",
    "note2 = \"ED Psych Progress Note  Pt slept overnight. Per Dr. Han's note pt was not expressing any SI or HI and admitted she wanted simply to sleep. Pt abusing crack cocaine and said she had not slept in 2 days. Pt awoken this AM, given food which she threw on the floor. Pt refusing to get dressed, stating she would leave \"\"on (her own time.\"\" Shouting and cursing at resident MD and security staff. Pt requiring security to re-direct her to get dressed. Pt finally agreeing to get dressed and is escorted out of the ER with security.    Impression: Cocaine intoxication and dependence. No acute suicidal or homicidal ideas and would not benefit from inpatient psychiatric admission and is not seeking admission.    Plan: Discharge. Will provide with list of referral for walk-in clinics, shelters and substance treatment programs.\"\n",
    "note1_split = note1.split('.')\n",
    "note1_split = [x for x in note1_split if x != '']\n",
    "note1_sentiment = sentiment_task(note1_split)\n",
    "note1_results = pd.DataFrame(note1_sentiment)\n",
    "\n",
    "note2_split = note2.split('.')\n",
    "note2_split = [x for x in note2_split if x != '']\n",
    "note2_sentiment = sentiment_task(note2_split)\n",
    "note2_results = pd.DataFrame(note2_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ED Psych Progress Note  Received sign out from day ED team', ' Pt with h/o bipolar disorder was BIB GM after pt repeatedly tried to run away from home, has not been compliant with treatment and has decompensated psychiatrically', '  Has appeared oddly related with pressured speech and delusional thought content', '  Tonight pt repeatedly asked to be seen, said she really thinks that she is pregnant and believes that she is ovulating, asking for pre-natal vitamin', '  She continues to have pressured speech and at times talked about suing multiple people, and said she has proved to the supreme court that she is not psychiatrically ill', '  She is fidgety but does not have any psychomotor agitation currently', '    Pt is in need of admission but no adolescent bed available tonight', '  Will continue to observe pt in ED and admit vs transfer in AM pending bed availability'] \n",
      "      label     score\n",
      "0  LABEL_1  0.999967\n",
      "1  LABEL_1  0.999970\n",
      "2  LABEL_1  0.999962\n",
      "3  LABEL_1  0.999970\n",
      "4  LABEL_1  0.999910\n",
      "5  LABEL_1  0.999961\n",
      "6  LABEL_1  0.999956\n",
      "7  LABEL_1  0.999965 \n",
      " ['ED Psych Progress Note  Pt slept overnight', ' Per Dr', \" Han's note pt was not expressing any SI or HI and admitted she wanted simply to sleep\", ' Pt abusing crack cocaine and said she had not slept in 2 days', ' Pt awoken this AM, given food which she threw on the floor', ' Pt refusing to get dressed, stating she would leave on (her own time', ' Shouting and cursing at resident MD and security staff', ' Pt requiring security to re-direct her to get dressed', ' Pt finally agreeing to get dressed and is escorted out of the ER with security', '    Impression: Cocaine intoxication and dependence', ' No acute suicidal or homicidal ideas and would not benefit from inpatient psychiatric admission and is not seeking admission', '    Plan: Discharge', ' Will provide with list of referral for walk-in clinics, shelters and substance treatment programs'] \n",
      "       label     score\n",
      "0   LABEL_1  0.999965\n",
      "1   LABEL_1  0.999498\n",
      "2   LABEL_1  0.999947\n",
      "3   LABEL_1  0.999871\n",
      "4   LABEL_1  0.999966\n",
      "5   LABEL_1  0.999965\n",
      "6   LABEL_1  0.999969\n",
      "7   LABEL_1  0.999968\n",
      "8   LABEL_1  0.999966\n",
      "9   LABEL_1  0.999945\n",
      "10  LABEL_1  0.748668\n",
      "11  LABEL_1  0.999954\n",
      "12  LABEL_1  0.999970\n"
     ]
    }
   ],
   "source": [
    "print(note1_split, '\\n', \n",
    "      note1_results, '\\n',\n",
    "      note2_split, '\\n', \n",
    "      note2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
