{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e22ed0e6-3c2a-4c8f-b0cf-93cc397bf85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, \\\n",
    "    DataCollatorWithPadding, EarlyStoppingCallback, set_seed\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "from pynvml import *\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used // 1024 ** 2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['sentence'], truncation=True, max_length=128)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    print(logits)\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    print(predictions)\n",
    "    scmetrics.add_batch(predictions=predictions, references=labels)\n",
    "    return scmetrics.compute()\n",
    "\n",
    "\n",
    "def create_labels(sentiment):\n",
    "    labels = []\n",
    "    for s in sentiment:\n",
    "        if s == 'neutral':\n",
    "            labels += [0]\n",
    "        elif s == 'negative':\n",
    "            labels += [1]\n",
    "        else:\n",
    "            labels += [2]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c01139b-f2da-46a4-8be2-f1244e9c7d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description='Sentence classification task')\n",
    "# parser.add_argument('--model', help='Path to pt model and tokenizer')\n",
    "# config = parser.parse_args(sys.argv[1:])\n",
    "# task = 'sentiment'\n",
    "# MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\" #minerva: download model from hugging face and put in folder, update to path\n",
    "MODEL = 'UFNLP/gatortron-base'\n",
    "\n",
    "seed = 47\n",
    "# set seed\n",
    "\n",
    "# Create task Dataset from annotated samples\n",
    "sentences = pd.read_csv('../data/sentences_MD-labels.csv', header=0)\n",
    "sentences = sentences[['language', \"MD_label\"]]\n",
    "\n",
    "dataset = Dataset.from_pandas(sentences).rename_columns({'language': 'sentence', \"MD_label\": 'sentiment'})\n",
    "dataset = dataset.add_column('label', create_labels(dataset['sentiment']))\n",
    "train_test = dataset.train_test_split(0.35, seed = seed)\n",
    "dev_test = train_test['test'].train_test_split(0.5, seed = seed)\n",
    "label_dt = DatasetDict({\n",
    "    'train': train_test['train'],\n",
    "    'dev': dev_test['train'],\n",
    "    'test': dev_test['test']})\n",
    "\n",
    "#print(label_dt)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tkn_dt = label_dt.map(tokenize_function, batched=True, num_proc=4) # batched tokenizing activated\n",
    "# tkn_dt = tkn_dt.remove_columns(['']) # at some point we might need to delete sentiment column or else get an error\n",
    "\n",
    "# data loader = allows us to use a chunk of the data at a time while training (or else computer crashes)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # read the sentences and pad them to create equal length vectors\n",
    "\n",
    "# {'sentence': ['Pt angry and has hx of making suicidal threats to be admitted and homicidal threats to staff', \n",
    "# 'Primary team will need to complete more thorough physical exam when pt is cooperative', \n",
    "# '55 yo male with XXX, h/o asthma, BIB police for threatening behavior, disorganization and paranoia in the setting of medication non-adherence'], \n",
    "# 'sentiment': ['negative', 'neutral', 'neutral'], 'label': [1, 0, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7c6849-893b-43ba-95bb-666256fa4b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../runs/ta_pretraining/checkpoint-435 were not used when initializing MegatronBertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing MegatronBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MegatronBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MegatronBertForSequenceClassification were not initialized from the model checkpoint at ../runs/ta_pretraining/checkpoint-435 and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# set seed\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed_all(seed)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=3) #\"runs/ta_pretraining/checkpoint-30\")\n",
    "set_seed(seed)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"../runs/ta_pretraining/checkpoint-435\",\n",
    "                                                           num_labels=3,\n",
    "                                                           from_tf=False)\n",
    "#print(model.classifier.weight)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda') # put the model on the gpu once, and then add a batch everytime when doing a training or evaluation loop\n",
    "    print_gpu_utilization()\n",
    "\n",
    "# Parameter containing:\n",
    "# tensor([[ 0.0020,  0.0379, -0.0100,  ...,  0.0229, -0.0006,  0.0331],\n",
    "#         [-0.0011,  0.0355, -0.0355,  ..., -0.0338, -0.0351,  0.0187],\n",
    "#         [-0.0078, -0.0093,  0.0046,  ..., -0.0050,  0.0078,  0.0083]],\n",
    "#        requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "327a7b9e-ba84-4e00-ac6a-46e1b3ad592d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'batch_size': 4, 'epochs': 1, 'learning_rate': 5e-06, 'warmup_ratio': 0, 'weight_decay': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/multiprocessing/resource_tracker.py:96: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.843100</td>\n",
       "      <td>1.055397</td>\n",
       "      <td>0.298611</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24643846  0.44475046 -0.27852887]\n",
      " [ 0.03377298  0.4484431  -0.15332578]\n",
      " [-0.15327331  0.4498885  -0.13395691]\n",
      " [-0.06329036  0.3284466  -0.24221198]\n",
      " [-0.15327331  0.4498885  -0.13395691]\n",
      " [-0.24585904  0.33180955 -0.01563188]\n",
      " [-0.07541206  0.44839683 -0.07367583]\n",
      " [-0.06438987 -0.01636753  0.54761535]]\n",
      "[1 1 1 1 1 1 1 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.29      1.00      0.44         2\n",
      "           2       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.43      0.44      0.31         8\n",
      "weighted avg       0.45      0.38      0.30         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/multiprocessing/resource_tracker.py:96: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24643846  0.44475046 -0.27852887]\n",
      " [ 0.03377298  0.4484431  -0.15332578]\n",
      " [-0.15327331  0.4498885  -0.13395691]\n",
      " [-0.06329036  0.3284466  -0.24221198]\n",
      " [-0.15327331  0.4498885  -0.13395691]\n",
      " [-0.24585904  0.33180955 -0.01563188]\n",
      " [-0.07541206  0.44839683 -0.07367583]\n",
      " [-0.06438987 -0.01636753  0.54761535]]\n",
      "[1 1 1 1 1 1 1 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.29      1.00      0.44         2\n",
      "           2       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.43      0.44      0.31         8\n",
      "weighted avg       0.45      0.38      0.30         8\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best parameters configuration: {'batch_size': 4, 'epochs': 1, 'learning_rate': 5e-06, 'warmup_ratio': 0, 'weight_decay': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/multiprocessing/resource_tracker.py:96: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22996509  0.36791444 -0.09549546]\n",
      " [-0.20772044  0.38608065 -0.1996097 ]\n",
      " [-0.11616159  0.30268916 -0.14674628]\n",
      " [-0.01101485  0.52304184 -0.41169962]\n",
      " [-0.02794262  0.27597213 -0.06334361]\n",
      " [ 0.14120705  0.08334071  0.30848563]\n",
      " [ 0.05568197  0.43057802 -0.4778656 ]\n",
      " [-0.04794928  0.32406083  0.07247816]\n",
      " [-0.14737171  0.5402084  -0.27447802]]\n",
      "[1 1 1 1 1 2 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.44         9\n",
      "   macro avg       0.46      0.44      0.35         9\n",
      "weighted avg       0.46      0.44      0.35         9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22996509  0.36791444 -0.09549546]\n",
      " [-0.20772044  0.38608065 -0.1996097 ]\n",
      " [-0.11616159  0.30268916 -0.14674628]\n",
      " [-0.01101485  0.52304184 -0.41169962]\n",
      " [-0.02794262  0.27597213 -0.06334361]\n",
      " [ 0.14120705  0.08334071  0.30848563]\n",
      " [ 0.05568197  0.43057802 -0.4778656 ]\n",
      " [-0.04794928  0.32406083  0.07247816]\n",
      " [-0.14737171  0.5402084  -0.27447802]]\n",
      "[1 1 1 1 1 2 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.38      1.00      0.55         3\n",
      "           2       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.44         9\n",
      "   macro avg       0.46      0.44      0.35         9\n",
      "weighted avg       0.46      0.44      0.35         9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 1.0360409021377563, 'test_f1': 0.34848484848484845, 'test_precision': 0.4583333333333333, 'test_recall': 0.4444444444444444, 'test_runtime': 1.6205, 'test_samples_per_second': 5.554, 'test_steps_per_second': 1.851}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters (for best configuration selection)\n",
    "# 1st evaluate the hyper parameters once at a time, and select each hyper parameter that gives you the best score on results aka F1 vs recall\n",
    "params = {\n",
    "    'batch_size': [4],\n",
    "    'epochs': [1],# 2, 5],\n",
    "    'learning_rate': [5e-6],# 1e-5, 2e-5, 5e-5, 1e-4],\n",
    "    'weight_decay': [0],# 0.01, 0.1], # how much the weight change is shrinking\n",
    "    'warmup_ratio': [0],# 0.01, 0.1] # ratio of examples it takes to get ready for the learning rate\n",
    "} \n",
    "\n",
    "metrics_file = f'classification_metrics_MD.csv'\n",
    "if os.path.isfile(metrics_file):\n",
    "    f = open(metrics_file, 'a')\n",
    "else:\n",
    "    f = open(metrics_file, 'w')\n",
    "    f.write('batch_size,epochs,learning_rate,weight_decay,warmup_ratio,loss,f1,precision,recall\\n')\n",
    "\n",
    "best_model = []\n",
    "best_f1 = 0.0\n",
    "tmp_trainer, tmp_comb = None, None\n",
    "for comb in list(ParameterGrid(params)):\n",
    "    print(f\"Parameters: {comb}\")\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'runs/MD',\n",
    "        evaluation_strategy='epoch', # every epoch the model is evaluated and checkpoint is made saving the weights\n",
    "        eval_steps=1, # check, probably each step is by epoch\n",
    "        logging_strategy='epoch',\n",
    "        weight_decay=comb['weight_decay'],\n",
    "        warmup_ratio=comb['warmup_ratio'],\n",
    "        num_train_epochs=comb['epochs'],\n",
    "        learning_rate=comb['learning_rate'],\n",
    "        per_device_train_batch_size=comb['batch_size'],\n",
    "        per_device_eval_batch_size=comb['batch_size'],\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='eval_f1',\n",
    "        seed=seed,\n",
    "        data_seed=seed)\n",
    "    scmetrics = evaluate.load(\"../scmetrics\")\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                      args=training_args,\n",
    "                      callbacks=[EarlyStoppingCallback(early_stopping_patience=3)], # if loss isnt decreasing for 2 epochs then it stops training\n",
    "                      train_dataset=tkn_dt['train'],\n",
    "                      eval_dataset=tkn_dt['dev'],\n",
    "                      compute_metrics=compute_metrics,\n",
    "                      data_collator=data_collator)\n",
    "    results = trainer.train()\n",
    "    results_eval = trainer.evaluate()\n",
    "\n",
    "    v = [comb['batch_size'], comb['epochs'], comb['learning_rate'], comb['weight_decay'], comb['warmup_ratio'],\n",
    "    results.metrics['train_loss'], results_eval['eval_f1'], results_eval['eval_precision'], results_eval['eval_recall']]\n",
    "    f.write(','.join([str(el) for el in v]) + '\\n')\n",
    "\n",
    "    if results_eval['eval_f1'] > best_f1:\n",
    "        best_f1 = results_eval['eval_f1']\n",
    "        tmp_trainer = trainer\n",
    "        tmp_comb = comb\n",
    "    print('-' * 100)\n",
    "    print('\\n\\n')\n",
    "\n",
    "# Error analysis step\n",
    "labels_to_sen = {0: 'neutral', 1: 'negative', 2: 'positive'}\n",
    "if tmp_trainer is not None:\n",
    "    best_trainer = tmp_trainer\n",
    "    best_comb = tmp_comb\n",
    "    print(f'Best parameters configuration: {best_comb}')\n",
    "    dev_pred = best_trainer.predict(tkn_dt['test'])\n",
    "    pred = np.argmax(dev_pred.predictions, axis=-1)\n",
    "    pred_score = np.max(torch.nn.functional.softmax(torch.tensor(dev_pred.predictions), dim=-1).numpy(), axis=-1)\n",
    "    i = 0\n",
    "    errors = {'FP': [], 'FN': []}\n",
    "    for pred_lab, true_lab in zip(pred, dev_pred.label_ids):\n",
    "        if pred_lab != true_lab:\n",
    "            if pred_lab > 1:\n",
    "                errors['FP'].append((\n",
    "                    tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(tkn_dt['test']['input_ids'][i])),\n",
    "                    pred_score[i], labels_to_sen[pred_lab], labels_to_sen[true_lab]))\n",
    "            else:\n",
    "                errors['FN'].append((tokenizer.convert_tokens_to_string(\n",
    "                    tokenizer.convert_ids_to_tokens(tkn_dt['test']['input_ids'][i])), pred_score[i],\n",
    "                                     labels_to_sen[pred_lab], labels_to_sen[true_lab]))\n",
    "        i += 1\n",
    "    with open(f'error_analysis_MD.tsv',\n",
    "              'w') as f:\n",
    "        f.write('sentence\\tpredicted_label\\ttrue_label\\tprobability\\n')\n",
    "        for k, vect in errors.items():\n",
    "            if k == 'FP':\n",
    "                for sen in vect:\n",
    "                    f.write(sen[0] + '\\t' + f'PRED_{sen[2].upper()}' + '\\t' + f'TRUE_{sen[3].upper()}' + '\\t' + str(\n",
    "                        sen[1]) + '\\n')\n",
    "                f.write('\\n')\n",
    "            else:\n",
    "                for sen in vect:\n",
    "                    f.write(sen[0] + '\\t' + f'PRED_{sen[2].upper()}' + '\\t' + f'TRUE_{sen[3].upper()}' + '\\t' + str(\n",
    "                        sen[1]) + '\\n')\n",
    "    test_pred = best_trainer.predict(tkn_dt['test'])\n",
    "    print(test_pred.metrics)\n",
    "\n",
    "    model_dir = f'runs/MD'\n",
    "    for d in os.listdir(model_dir):\n",
    "        # This removes the checkpoints (comment it if you want to keep them)\n",
    "        if 'checkpoint' in d:\n",
    "            shutil.rmtree(os.path.join(model_dir, d))\n",
    "    best_trainer.save_model(\n",
    "        output_dir=f'best_model/MD')\n",
    "else:\n",
    "    print(\"Precision is 0.0 change something in your model's configuration and retry.\")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13de640a-ab7a-4b09-a452-26b0b28589a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93850b80-f2cf-46d9-9e3c-437ebd88ddb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
