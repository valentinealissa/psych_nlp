{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6881e477-b624-45bd-9115-1bb223a6afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import DatasetDict, Dataset, load_metric\n",
    "import random\n",
    "from transformers import BartTokenizerFast, BartForSequenceClassification, Trainer, TrainingArguments, \\\n",
    "EvalPrediction, pipeline, set_seed, DataCollatorWithPadding, EarlyStoppingCallback\n",
    "import os\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import classification_report\n",
    "import argparse\n",
    "import sys\n",
    "import shutil\n",
    "import evaluate\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "MODEL = 'facebook/bart-large-mnli'\n",
    "tokenizer = BartTokenizerFast.from_pretrained(MODEL)\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used // 1024 ** 2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()\n",
    "\n",
    "    \n",
    "def create_input_sequence(sample):\n",
    "    text = sample[\"text\"]\n",
    "    label = sample[\"class\"][0]\n",
    "    contradiction_label = random.choice([x for x in label_to_int if x != label])\n",
    "    encoded_sequence = tokenizer(text * 2, [template.format(label), template.format(contradiction_label)], truncation = True, padding = 'max_length')\n",
    "    encoded_sequence[\"labels\"] = [1, 0]\n",
    "    encoded_sequence[\"input_sentence\"] = tokenizer.batch_decode(encoded_sequence.input_ids)\n",
    "    return encoded_sequence\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    metric_acc = load_metric(\"accuracy\")\n",
    "    metric_f1 = load_metric(\"f1\")\n",
    "    metric_precision = load_metric(\"precision\")\n",
    "    metric_recall = load_metric(\"recall\")\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis = 1)\n",
    "    result = {}\n",
    "    result[\"accuracy\"] = metric_acc.compute(predictions = preds, references = p.label_ids)[\"accuracy\"]\n",
    "    result[\"f1\"] = metric_f1.compute(predictions = preds, references = p.label_ids, pos_label=1, average = \"weighted\")[\"f1\"] #play with \"weighted\" \"micro\" \"macro\"\n",
    "    result[\"precision\"] = metric_precision.compute(predictions = preds, references = p.label_ids, pos_label=1, average=\"weighted\", sample_weight=None, zero_division='warn')[\"precision\"]\n",
    "    result[\"recall\"] = metric_recall.compute(predictions = preds, references = p.label_ids, pos_label=1, average=\"weighted\", sample_weight=None, zero_division='warn')[\"recall\"]\n",
    "    c = classification_report(predictions = preds, references = p.label_ids, labels=None)\n",
    "    print(c)\n",
    "    return result\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     print(logits)\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     scmetrics.add_batch(predictions=predictions, references=labels)\n",
    "#     return scmetrics.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e821ac95-7333-470c-b22f-ef4e534bf102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description='Sentence classification task')\n",
    "# parser.add_argument('--model', help='Path to pt model and tokenizer')\n",
    "# config = parser.parse_args(sys.argv[1:])\n",
    "# task = 'sentiment'\n",
    "# MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\" #minerva: download model from hugging face and put in folder, update to path\n",
    "\n",
    "df = pd.read_csv('../data/MD-NLI.csv', header=0)\n",
    "df = df[[\"language\", \"MD_label\"]]\n",
    "dataset = Dataset.from_pandas(df).rename_columns({'language': 'text', \"MD_label\": 'class'})\n",
    "# label_dt = dataset.train_test_split(0.5, seed = seed)\n",
    "train_test = dataset.train_test_split(0.35, seed = seed)\n",
    "dev_test = train_test['test'].train_test_split(0.5, seed = seed)\n",
    "label_dt = DatasetDict({\n",
    "    'train': train_test['train'],\n",
    "    'dev': dev_test['train'],\n",
    "    'test': dev_test['test']})\n",
    "# print(label_dt)\n",
    "\n",
    "label_to_int = [\"neutral\", \"negative\", \"positive\"]\n",
    "template = \"The sentiment of this sentence is {}\"\n",
    "label_dt = label_dt.map(create_input_sequence, batched = True, batch_size = 1, remove_columns = [\"class\", \"text\"])\n",
    "\n",
    "# data loader = allows us to use a chunk of the data at a time while training (or else computer crashes)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # read the sentences and pad them to create equal length vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7f5223d-f8bd-4652-83b4-65bb6c8df469",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartForSequenceClassification.from_pretrained(MODEL, num_labels = len(label_to_int), from_tf=False)\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda') # put the model on the gpu once, and then add a batch everytime when doing a training or evaluation loop\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2be4e263-2841-4ff6-978f-e2ed7fb02eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/multiprocessing/resource_tracker.py:96: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'batch_size': 4, 'epochs': 1, 'learning_rate': 1e-05, 'warmup_ratio': 0.01, 'weight_decay': 0.01}\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 17:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.053600</td>\n",
       "      <td>0.634657</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xm/m4dy5bvs1fn7fb9wxjhsg4dc0000gn/T/ipykernel_1213/1554091589.py:45: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric_acc = load_metric(\"accuracy\")\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/multiprocessing/resource_tracker.py:96: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/multiprocessing/resource_tracker.py:96: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Parameters: {'batch_size': 4, 'epochs': 3, 'learning_rate': 1e-05, 'warmup_ratio': 0.01, 'weight_decay': 0.01}\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 48:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.146800</td>\n",
       "      <td>0.903124</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.676113</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.451400</td>\n",
       "      <td>0.732622</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.690403</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/multiprocessing/resource_tracker.py:96: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/multiprocessing/resource_tracker.py:96: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Parameters: {'batch_size': 4, 'epochs': 5, 'learning_rate': 1e-05, 'warmup_ratio': 0.01, 'weight_decay': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 1:20:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.210900</td>\n",
       "      <td>1.556046</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>2.045304</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.219300</td>\n",
       "      <td>2.062227</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>1.564705</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.555955</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/multiprocessing/resource_tracker.py:96: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/multiprocessing/resource_tracker.py:96: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best parameters configuration: {'batch_size': 4, 'epochs': 5, 'learning_rate': 1e-05, 'warmup_ratio': 0.01, 'weight_decay': 0.01}\n",
      "{'test_loss': 2.0217905044555664, 'test_accuracy': 0.6666666666666666, 'test_f1': 0.6666666666666666, 'test_precision': 0.6666666666666666, 'test_recall': 0.6666666666666666, 'test_runtime': 69.6513, 'test_samples_per_second': 0.258, 'test_steps_per_second': 0.072}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters (for best configuration selection)\n",
    "# 1st evaluate the hyper parameters once at a time, and select each hyper parameter that gives you the best score on results aka F1 vs recall\n",
    "params = {\n",
    "    'batch_size': [4], #[4, 8],\n",
    "    'epochs': [1, 3, 5], # [2, 3, 4, 5],\n",
    "    'learning_rate': [1e-5], # [5e-6, 1e-5, 2e-5, 3e-5],\n",
    "    'weight_decay': [0.01], # [0, 0.01, 0.1], # how much the weight change is shrinking\n",
    "    'warmup_ratio': [0.01], #[0, 0.01, 0.1] # ratio of examples it takes to get ready for the learning rate\n",
    "} \n",
    "\n",
    "metrics_file = f'classification_metrics_MD.csv'\n",
    "if os.path.isfile(metrics_file):\n",
    "    f = open(metrics_file, 'a')\n",
    "else:\n",
    "    f = open(metrics_file, 'w')\n",
    "    f.write('batch_size,epochs,learning_rate,weight_decay,warmup_ratio,loss,accuracy,f1,precision,recall\\n')\n",
    "\n",
    "best_model = []\n",
    "best_f1 = 0.0\n",
    "tmp_trainer, tmp_comb = None, None\n",
    "for comb in list(ParameterGrid(params)):\n",
    "    print(f\"Parameters: {comb}\")\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'runs/MD',\n",
    "        evaluation_strategy='epoch', # every epoch the model is evaluated and checkpoint is made saving the weights\n",
    "        eval_steps=1, # check, probably each step is by epoch\n",
    "        logging_strategy='epoch',\n",
    "        weight_decay=comb['weight_decay'],\n",
    "        warmup_ratio=comb['warmup_ratio'],\n",
    "        num_train_epochs=comb['epochs'],\n",
    "        learning_rate=comb['learning_rate'],\n",
    "        per_device_train_batch_size=comb['batch_size'],\n",
    "        per_device_eval_batch_size=comb['batch_size'],\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='eval_f1',\n",
    "        adam_epsilon=1e-6,\n",
    "        seed=seed,\n",
    "        data_seed=seed)\n",
    "    # scmetrics = evaluate.load(\"../scmetrics\")\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                      args=training_args,\n",
    "                      callbacks=[EarlyStoppingCallback(early_stopping_patience=3)], # if loss isnt decreasing for 2 epochs then it stops training\n",
    "                      train_dataset=label_dt['train'],\n",
    "                      eval_dataset=label_dt['dev'],\n",
    "                      compute_metrics=compute_metrics,\n",
    "                      data_collator=data_collator)\n",
    "    results = trainer.train()\n",
    "    results_eval = trainer.evaluate()\n",
    "\n",
    "    v = [comb['batch_size'], comb['epochs'], comb['learning_rate'], comb['weight_decay'], comb['warmup_ratio'],\n",
    "    results_eval['eval_loss'], results_eval['eval_accuracy'], results_eval['eval_f1'], results_eval['eval_precision'], results_eval['eval_recall']]\n",
    "    f.write(','.join([str(el) for el in v]) + '\\n')\n",
    "\n",
    "    if results_eval['eval_f1'] > best_f1:\n",
    "        best_f1 = results_eval['eval_f1']\n",
    "        tmp_trainer = trainer\n",
    "        tmp_comb = comb\n",
    "    print('-' * 100)\n",
    "    print('\\n\\n')\n",
    "\n",
    "# Error analysis step\n",
    "labels_to_sen = {0: 'neutral', 1: 'negative', 2: 'positive'}\n",
    "if tmp_trainer is not None:\n",
    "    best_trainer = tmp_trainer\n",
    "    best_comb = tmp_comb\n",
    "    print(f'Best parameters configuration: {best_comb}')\n",
    "    # dev_pred = best_trainer.predict(tkn_dt['test'])\n",
    "    # pred = np.argmax(dev_pred.predictions, axis=-1)\n",
    "    # pred_score = np.max(torch.nn.functional.softmax(torch.tensor(dev_pred.predictions), dim=-1).numpy(), axis=-1)\n",
    "    # i = 0\n",
    "    # errors = {'FP': [], 'FN': []}\n",
    "    # for pred_lab, true_lab in zip(pred, dev_pred.label_ids):\n",
    "    #     if pred_lab != true_lab:\n",
    "    #         if pred_lab > 1:\n",
    "    #             errors['FP'].append((\n",
    "    #                 tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(tkn_dt['test']['input_ids'][i])),\n",
    "    #                 pred_score[i], labels_to_sen[pred_lab], labels_to_sen[true_lab]))\n",
    "    #         else:\n",
    "    #             errors['FN'].append((tokenizer.convert_tokens_to_string(\n",
    "    #                 tokenizer.convert_ids_to_tokens(tkn_dt['test']['input_ids'][i])), pred_score[i],\n",
    "    #                                  labels_to_sen[pred_lab], labels_to_sen[true_lab]))\n",
    "    #     i += 1\n",
    "    # with open(f'error_analysis_MD.tsv',\n",
    "    #           'w') as f:\n",
    "    #     f.write('sentence\\tpredicted_label\\ttrue_label\\tprobability\\n')\n",
    "    #     for k, vect in errors.items():\n",
    "    #         if k == 'FP':\n",
    "    #             for sen in vect:\n",
    "    #                 f.write(sen[0] + '\\t' + f'PRED_{sen[2].upper()}' + '\\t' + f'TRUE_{sen[3].upper()}' + '\\t' + str(\n",
    "    #                     sen[1]) + '\\n')\n",
    "    #             f.write('\\n')\n",
    "    #         else:\n",
    "    #             for sen in vect:\n",
    "    #                 f.write(sen[0] + '\\t' + f'PRED_{sen[2].upper()}' + '\\t' + f'TRUE_{sen[3].upper()}' + '\\t' + str(\n",
    "    #                     sen[1]) + '\\n')\n",
    "    test_pred = best_trainer.predict(label_dt['test'])\n",
    "    print(test_pred.metrics)\n",
    "\n",
    "    model_dir = f'runs/MD'\n",
    "    # for d in os.listdir(model_dir):\n",
    "        # This removes the checkpoints (comment it if you want to keep them)\n",
    "        # if 'checkpoint' in d:\n",
    "        #     shutil.rmtree(os.path.join(model_dir, d))\n",
    "    best_trainer.save_model(\n",
    "        output_dir=f'best_model/MD')\n",
    "else:\n",
    "    print(\"Precision is 0.0 change something in your model's configuration and retry.\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d11ca-ac15-43b2-acb4-7fb96a479831",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best parameters configuration 7/31/23: {'batch_size': 4, 'epochs': 5, 'learning_rate': 5e-06, 'warmup_ratio': 0, 'weight_decay': 0}\n",
    "{'test_loss': 2.9686105251312256, 'test_accuracy': 0.7291666666666666, 'test_f1': 0.7261956998683634, 'test_precision': 0.7395644283121596, \n",
    " 'test_recall': 0.7291666666666666, 'test_runtime': 178.2779, 'test_samples_per_second': 0.269, 'test_steps_per_second': 0.067}\n",
    "\n",
    "Best parameters configuration 8/2/23: {'batch_size': 4, 'epochs': 2, 'learning_rate': 5e-06, 'warmup_ratio': 0, 'weight_decay': 0.1}\n",
    "{'test_loss': 2.897099256515503, 'test_accuracy': 0.7291666666666666, 'test_f1': 0.7290490664350848, 'test_precision': 0.7295652173913044, \n",
    " 'test_recall': 0.7291666666666666, 'test_runtime': 176.8441, 'test_samples_per_second': 0.271, 'test_steps_per_second': 0.068}\n",
    "\n",
    "Best parameters configuration 8/7/23: {'batch_size': 4, 'epochs': 5, 'learning_rate': 1e-05, 'warmup_ratio': 0.01, 'weight_decay': 0.01}\n",
    "{'test_loss': 2.0217905044555664, 'test_accuracy': 0.6666666666666666, 'test_f1': 0.6666666666666666, 'test_precision': 0.6666666666666666, \n",
    " 'test_recall': 0.6666666666666666, 'test_runtime': 69.6513, 'test_samples_per_second': 0.258, 'test_steps_per_second': 0.072}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f8f64ce-c6a7-45ba-8771-5746ceb89ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters configuration: {'batch_size': 4, 'epochs': 2, 'learning_rate': 5e-06, 'warmup_ratio': 0, 'weight_decay': 0.1}\n",
      "{'test_loss': 2.897099256515503, 'test_accuracy': 0.7291666666666666, 'test_f1': 0.7290490664350848, 'test_precision': 0.7295652173913044, 'test_recall': 0.7291666666666666, 'test_runtime': 176.8441, 'test_samples_per_second': 0.271, 'test_steps_per_second': 0.068}\n"
     ]
    }
   ],
   "source": [
    "# labels_to_sen = {0: 'neutral', 1: 'negative', 2: 'positive'}\n",
    "if tmp_trainer is not None:\n",
    "    best_trainer = tmp_trainer\n",
    "    best_comb = tmp_comb\n",
    "    print(f'Best parameters configuration: {best_comb}')\n",
    "    # dev_pred = best_trainer.predict(tkn_dt['test'])\n",
    "    # pred = np.argmax(dev_pred.predictions, axis=-1)\n",
    "    # pred_score = np.max(torch.nn.functional.softmax(torch.tensor(dev_pred.predictions), dim=-1).numpy(), axis=-1)\n",
    "    # i = 0\n",
    "    # errors = {'FP': [], 'FN': []}\n",
    "    # for pred_lab, true_lab in zip(pred, dev_pred.label_ids):\n",
    "    #     if pred_lab != true_lab:\n",
    "    #         if pred_lab > 1:\n",
    "    #             errors['FP'].append((\n",
    "    #                 tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(tkn_dt['test']['input_ids'][i])),\n",
    "    #                 pred_score[i], labels_to_sen[pred_lab], labels_to_sen[true_lab]))\n",
    "    #         else:\n",
    "    #             errors['FN'].append((tokenizer.convert_tokens_to_string(\n",
    "    #                 tokenizer.convert_ids_to_tokens(tkn_dt['test']['input_ids'][i])), pred_score[i],\n",
    "    #                                  labels_to_sen[pred_lab], labels_to_sen[true_lab]))\n",
    "    #     i += 1\n",
    "    # with open(f'error_analysis_MD.tsv',\n",
    "    #           'w') as f:\n",
    "    #     f.write('sentence\\tpredicted_label\\ttrue_label\\tprobability\\n')\n",
    "    #     for k, vect in errors.items():\n",
    "    #         if k == 'FP':\n",
    "    #             for sen in vect:\n",
    "    #                 f.write(sen[0] + '\\t' + f'PRED_{sen[2].upper()}' + '\\t' + f'TRUE_{sen[3].upper()}' + '\\t' + str(\n",
    "    #                     sen[1]) + '\\n')\n",
    "    #             f.write('\\n')\n",
    "    #         else:\n",
    "    #             for sen in vect:\n",
    "    #                 f.write(sen[0] + '\\t' + f'PRED_{sen[2].upper()}' + '\\t' + f'TRUE_{sen[3].upper()}' + '\\t' + str(\n",
    "    #                     sen[1]) + '\\n')\n",
    "    test_pred = best_trainer.predict(label_dt['test'])\n",
    "    print(test_pred.metrics)\n",
    "\n",
    "    model_dir = f'runs/MD'\n",
    "    for d in os.listdir(model_dir):\n",
    "        # This removes the checkpoints (comment it if you want to keep them)\n",
    "        if 'checkpoint' in d:\n",
    "            shutil.rmtree(os.path.join(model_dir, d))\n",
    "    best_trainer.save_model(\n",
    "        output_dir=f'best_model/MD')\n",
    "else:\n",
    "    print(\"Precision is 0.0 change something in your model's configuration and retry.\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccc3665-0f89-4ab9-888a-d471156b38da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
