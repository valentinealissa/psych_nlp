{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6881e477-b624-45bd-9115-1bb223a6afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, \\\n",
    "    DataCollatorWithPadding, EarlyStoppingCallback, set_seed\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "from pynvml import *\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used // 1024 ** 2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()\n",
    "\n",
    "\n",
    "def tokenize_function1(examples):\n",
    "    return tokenizer(examples['premise'], truncation=True, max_length=128)\n",
    "\n",
    "def tokenize_function2(examples):\n",
    "    return tokenizer(examples['hypothesis'], truncation=True, max_length=128)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    print(logits)\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    scmetrics.add_batch(predictions=predictions, references=labels)\n",
    "    return scmetrics.compute()\n",
    "\n",
    "\n",
    "def create_labels(str_label):\n",
    "    labels = []\n",
    "    for s in str_label:\n",
    "        if s == 'entailment':\n",
    "            labels += [0]\n",
    "        else:\n",
    "            labels += [1]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e821ac95-7333-470c-b22f-ef4e534bf102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/23 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/23 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description='Sentence classification task')\n",
    "# parser.add_argument('--model', help='Path to pt model and tokenizer')\n",
    "# config = parser.parse_args(sys.argv[1:])\n",
    "# task = 'sentiment'\n",
    "# MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\" #minerva: download model from hugging face and put in folder, update to path\n",
    "MODEL = 'facebook/bart-large-mnli'\n",
    "\n",
    "seed = 42\n",
    "# set seed\n",
    "\n",
    "# Create task Dataset from annotated samples\n",
    "sentences = pd.read_csv('../data/MD-NLI.csv', header=0)\n",
    "\n",
    "dataset = Dataset.from_pandas(sentences).rename_columns({'language': 'premise', \"MD_label\": 'sentiment', \"label\": 'str_label'})\n",
    "dataset = dataset.add_column('label', create_labels(dataset['str_label']))\n",
    "train_test = dataset.train_test_split(0.5, seed = seed)\n",
    "dev_test = train_test['test'].train_test_split(0.5, seed = seed)\n",
    "label_dt = DatasetDict({\n",
    "    'train': train_test['train'],\n",
    "    'dev': dev_test['train'],\n",
    "    'test': dev_test['test']})\n",
    "\n",
    "# print(label_dt)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "tkn_dt = label_dt.map(tokenize_function1, batched=True, num_proc=4) # batched tokenizing activated\n",
    "tkn_dt = label_dt.map(tokenize_function2, batched=True, num_proc=4)\n",
    "# tkn_dt = tkn_dt.remove_columns(['']) # at some point we might need to delete sentiment column or else get an error\n",
    "\n",
    "# data loader = allows us to use a chunk of the data at a time while training (or else computer crashes)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # read the sentences and pad them to create equal length vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7f5223d-f8bd-4652-83b4-65bb6c8df469",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL,\n",
    "                                                           num_labels=3,\n",
    "                                                           from_tf=False)\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda') # put the model on the gpu once, and then add a batch everytime when doing a training or evaluation loop\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2be4e263-2841-4ff6-978f-e2ed7fb02eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/multiprocessing/resource_tracker.py:96: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n",
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'batch_size': 4, 'epochs': 1, 'learning_rate': 5e-06, 'warmup_ratio': 0, 'weight_decay': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.91953677,  0.8460272 , -2.0337613 ],\n",
      "       [ 0.9632044 ,  0.5826386 , -1.932817  ],\n",
      "       [ 0.9632041 ,  0.5826388 , -1.9328166 ],\n",
      "       [ 0.9632044 ,  0.5826386 , -1.932817  ],\n",
      "       [ 0.91953677,  0.8460272 , -2.0337613 ],\n",
      "       [ 0.80543125,  0.90705234, -1.8053453 ],\n",
      "       [ 0.80543137,  0.90705246, -1.8053449 ],\n",
      "       [ 0.9632044 ,  0.5826386 , -1.932817  ],\n",
      "       [ 0.80543137,  0.90705246, -1.8053449 ],\n",
      "       [ 0.9195366 ,  0.8460272 , -2.0337617 ],\n",
      "       [ 0.80543137,  0.90705246, -1.8053449 ],\n",
      "       [ 0.9632044 ,  0.5826386 , -1.932817  ]], dtype=float32), array([[[ 7.38023128e-03,  3.47783789e-02,  2.32912097e-02, ...,\n",
      "          6.59265649e-03,  1.00501385e-02,  6.89580571e-04],\n",
      "        [-1.18490063e-01, -2.23131254e-01, -2.65620619e-01, ...,\n",
      "         -1.38534203e-01,  1.13098696e-01, -1.86566785e-01],\n",
      "        [ 3.92207317e-02, -1.47638544e-01, -8.02371576e-02, ...,\n",
      "          2.10778806e-02,  8.07959437e-02, -6.27166405e-02],\n",
      "        ...,\n",
      "        [ 7.62153938e-02, -2.37712115e-01, -4.52162772e-01, ...,\n",
      "         -3.94392535e-02,  2.87013650e-01, -5.97414374e-02],\n",
      "        [-6.06861943e-03,  4.23886161e-03,  9.02863126e-03, ...,\n",
      "          7.62830675e-03, -1.97968632e-03, -1.28570339e-03],\n",
      "        [ 1.11329041e-01,  9.09673646e-02,  1.55039672e-02, ...,\n",
      "         -1.97037123e-02, -3.39803845e-02,  8.00589547e-02]],\n",
      "\n",
      "       [[ 7.65290577e-03,  3.53324600e-02,  2.32196376e-02, ...,\n",
      "          6.28798315e-03,  9.31882672e-03,  9.32850409e-04],\n",
      "        [-1.20530277e-01, -1.88704610e-01, -2.43863374e-01, ...,\n",
      "         -1.45535737e-01,  1.07896231e-01, -1.54204398e-01],\n",
      "        [-3.06590684e-02, -1.97832346e-01, -1.21290550e-01, ...,\n",
      "          3.27911251e-03,  7.81696215e-02, -6.27559721e-02],\n",
      "        ...,\n",
      "        [ 2.22455198e-03, -2.10554913e-01, -3.12403470e-01, ...,\n",
      "         -1.52982652e-01,  2.38034531e-01, -4.35663834e-02],\n",
      "        [-6.39838725e-03,  3.97454388e-03,  8.79794545e-03, ...,\n",
      "          7.25392997e-03, -2.85033789e-03, -1.43663469e-03],\n",
      "        [ 1.10853411e-01,  9.16303545e-02,  1.52572934e-02, ...,\n",
      "         -2.28528455e-02, -3.50580253e-02,  7.84364790e-02]],\n",
      "\n",
      "       [[ 7.65290577e-03,  3.53324600e-02,  2.32196376e-02, ...,\n",
      "          6.28798315e-03,  9.31882672e-03,  9.32850409e-04],\n",
      "        [-1.20530277e-01, -1.88704610e-01, -2.43863374e-01, ...,\n",
      "         -1.45535737e-01,  1.07896231e-01, -1.54204398e-01],\n",
      "        [-3.06590684e-02, -1.97832346e-01, -1.21290550e-01, ...,\n",
      "          3.27911251e-03,  7.81696215e-02, -6.27559721e-02],\n",
      "        ...,\n",
      "        [ 2.22455198e-03, -2.10554913e-01, -3.12403470e-01, ...,\n",
      "         -1.52982652e-01,  2.38034531e-01, -4.35663834e-02],\n",
      "        [-6.39838725e-03,  3.97454388e-03,  8.79794545e-03, ...,\n",
      "          7.25392997e-03, -2.85033789e-03, -1.43663469e-03],\n",
      "        [ 1.10853411e-01,  9.16303545e-02,  1.52572934e-02, ...,\n",
      "         -2.28528455e-02, -3.50580253e-02,  7.84364790e-02]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 7.38023128e-03,  3.47783789e-02,  2.32912097e-02, ...,\n",
      "          6.59265649e-03,  1.00501385e-02,  6.89580571e-04],\n",
      "        [-1.18490063e-01, -2.23131254e-01, -2.65620619e-01, ...,\n",
      "         -1.38534203e-01,  1.13098696e-01, -1.86566785e-01],\n",
      "        [ 3.92207317e-02, -1.47638544e-01, -8.02371576e-02, ...,\n",
      "          2.10778806e-02,  8.07959437e-02, -6.27166405e-02],\n",
      "        ...,\n",
      "        [ 7.62153938e-02, -2.37712115e-01, -4.52162772e-01, ...,\n",
      "         -3.94392535e-02,  2.87013650e-01, -5.97414374e-02],\n",
      "        [-6.06861943e-03,  4.23886161e-03,  9.02863126e-03, ...,\n",
      "          7.62830675e-03, -1.97968632e-03, -1.28570339e-03],\n",
      "        [ 1.11329041e-01,  9.09673646e-02,  1.55039672e-02, ...,\n",
      "         -1.97037123e-02, -3.39803845e-02,  8.00589547e-02]],\n",
      "\n",
      "       [[ 7.82152265e-03,  3.34026329e-02,  2.29246262e-02, ...,\n",
      "          6.99303020e-03,  9.71454568e-03,  2.74434220e-04],\n",
      "        [-6.81943670e-02, -1.59448326e-01, -2.17004463e-01, ...,\n",
      "         -1.44306690e-01,  1.14788473e-01, -1.38604030e-01],\n",
      "        [-9.66763590e-03, -1.68892220e-01, -1.06964841e-01, ...,\n",
      "         -1.74620096e-03,  6.34764060e-02, -6.24610595e-02],\n",
      "        ...,\n",
      "        [ 7.61681199e-02,  2.92460322e-01, -1.17209956e-01, ...,\n",
      "         -4.19819318e-02,  2.31468417e-02,  9.51130539e-02],\n",
      "        [-6.38226978e-03,  3.71232210e-03,  9.04575177e-03, ...,\n",
      "          7.52715115e-03, -2.02508364e-03, -1.82835734e-03],\n",
      "        [ 1.15518928e-01,  8.48088413e-02,  1.87993720e-02, ...,\n",
      "         -1.95495784e-02, -3.50930020e-02,  7.36262947e-02]],\n",
      "\n",
      "       [[ 7.65290577e-03,  3.53324600e-02,  2.32196376e-02, ...,\n",
      "          6.28798315e-03,  9.31882672e-03,  9.32850409e-04],\n",
      "        [-1.20530277e-01, -1.88704610e-01, -2.43863374e-01, ...,\n",
      "         -1.45535737e-01,  1.07896231e-01, -1.54204398e-01],\n",
      "        [-3.06590684e-02, -1.97832346e-01, -1.21290550e-01, ...,\n",
      "          3.27911251e-03,  7.81696215e-02, -6.27559721e-02],\n",
      "        ...,\n",
      "        [ 2.22455198e-03, -2.10554913e-01, -3.12403470e-01, ...,\n",
      "         -1.52982652e-01,  2.38034531e-01, -4.35663834e-02],\n",
      "        [-6.39838725e-03,  3.97454388e-03,  8.79794545e-03, ...,\n",
      "          7.25392997e-03, -2.85033789e-03, -1.43663469e-03],\n",
      "        [ 1.10853411e-01,  9.16303545e-02,  1.52572934e-02, ...,\n",
      "         -2.28528455e-02, -3.50580253e-02,  7.84364790e-02]]],\n",
      "      dtype=float32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (12,3) into shape (12,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 48\u001b[0m\n\u001b[1;32m     39\u001b[0m scmetrics \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../scmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     42\u001b[0m                   args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     43\u001b[0m                   callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)], \u001b[38;5;66;03m# if loss isnt decreasing for 2 epochs then it stops training\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m                   compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     47\u001b[0m                   data_collator\u001b[38;5;241m=\u001b[39mdata_collator)\n\u001b[0;32m---> 48\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m results_eval \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m     51\u001b[0m v \u001b[38;5;241m=\u001b[39m [comb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], comb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m], comb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m], comb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m], comb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarmup_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     52\u001b[0m results\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], results_eval[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_f1\u001b[39m\u001b[38;5;124m'\u001b[39m], results_eval[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_precision\u001b[39m\u001b[38;5;124m'\u001b[39m], results_eval[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_recall\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/trainer.py:1664\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1661\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1662\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1663\u001b[0m )\n\u001b[0;32m-> 1664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/trainer.py:2034\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2031\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2033\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2034\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2037\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/trainer.py:2300\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2298\u001b[0m         metrics\u001b[38;5;241m.\u001b[39mupdate(dataset_metrics)\n\u001b[1;32m   2299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2300\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2303\u001b[0m \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/trainer.py:3029\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3026\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3028\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3029\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3030\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3032\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3033\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3039\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/trainer.py:3318\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3314\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3315\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[1;32m   3316\u001b[0m         )\n\u001b[1;32m   3317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3318\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3320\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[37], line 39\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_pred)\u001b[0m\n\u001b[1;32m     37\u001b[0m logits, labels \u001b[38;5;241m=\u001b[39m eval_pred\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(logits)\n\u001b[0;32m---> 39\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m scmetrics\u001b[38;5;241m.\u001b[39madd_batch(predictions\u001b[38;5;241m=\u001b[39mpredictions, references\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scmetrics\u001b[38;5;241m.\u001b[39mcompute()\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/numpy/core/fromnumeric.py:1216\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/numpy/core/fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/numpy/core/fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m, method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (12,3) into shape (12,)"
     ]
    }
   ],
   "source": [
    "# Hyperparameters (for best configuration selection)\n",
    "# 1st evaluate the hyper parameters once at a time, and select each hyper parameter that gives you the best score on results aka F1 vs recall\n",
    "params = {\n",
    "    'batch_size': [4],\n",
    "    'epochs': [1], # 2, 5],\n",
    "    'learning_rate': [5e-6], # 1e-5, 2e-5, 5e-5, 1e-4],\n",
    "    'weight_decay': [0], # 0.01, 0.1], # how much the weight change is shrinking\n",
    "    'warmup_ratio': [0], # 0.01, 0.1] # ratio of examples it takes to get ready for the learning rate\n",
    "} \n",
    "\n",
    "metrics_file = f'classification_metrics_MD.csv'\n",
    "if os.path.isfile(metrics_file):\n",
    "    f = open(metrics_file, 'a')\n",
    "else:\n",
    "    f = open(metrics_file, 'w')\n",
    "    f.write('batch_size,epochs,learning_rate,weight_decay,warmup_ratio,loss,f1,precision,recall\\n')\n",
    "\n",
    "best_model = []\n",
    "best_f1 = 0.0\n",
    "tmp_trainer, tmp_comb = None, None\n",
    "for comb in list(ParameterGrid(params)):\n",
    "    print(f\"Parameters: {comb}\")\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'runs/MD',\n",
    "        evaluation_strategy='epoch', # every epoch the model is evaluated and checkpoint is made saving the weights\n",
    "        eval_steps=1, # check, probably each step is by epoch\n",
    "        logging_strategy='epoch',\n",
    "        weight_decay=comb['weight_decay'],\n",
    "        warmup_ratio=comb['warmup_ratio'],\n",
    "        num_train_epochs=comb['epochs'],\n",
    "        learning_rate=comb['learning_rate'],\n",
    "        per_device_train_batch_size=comb['batch_size'],\n",
    "        per_device_eval_batch_size=comb['batch_size'],\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='eval_f1',\n",
    "        seed=seed,\n",
    "        data_seed=seed)\n",
    "    scmetrics = evaluate.load(\"../scmetrics\")\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                      args=training_args,\n",
    "                      callbacks=[EarlyStoppingCallback(early_stopping_patience=3)], # if loss isnt decreasing for 2 epochs then it stops training\n",
    "                      train_dataset=tkn_dt['train'],\n",
    "                      eval_dataset=tkn_dt['dev'],\n",
    "                      compute_metrics=compute_metrics,\n",
    "                      data_collator=data_collator)\n",
    "    results = trainer.train()\n",
    "    results_eval = trainer.evaluate()\n",
    "\n",
    "    v = [comb['batch_size'], comb['epochs'], comb['learning_rate'], comb['weight_decay'], comb['warmup_ratio'],\n",
    "    results.metrics['train_loss'], results_eval['eval_f1'], results_eval['eval_precision'], results_eval['eval_recall']]\n",
    "    f.write(','.join([str(el) for el in v]) + '\\n')\n",
    "\n",
    "    if results_eval['eval_f1'] > best_f1:\n",
    "        best_f1 = results_eval['eval_f1']\n",
    "        tmp_trainer = trainer\n",
    "        tmp_comb = comb\n",
    "    print('-' * 100)\n",
    "    print('\\n\\n')\n",
    "\n",
    "# Error analysis step\n",
    "labels_to_sen = {0: 'neutral', 1: 'negative', 2: 'positive'}\n",
    "if tmp_trainer is not None:\n",
    "    best_trainer = tmp_trainer\n",
    "    best_comb = tmp_comb\n",
    "    print(f'Best parameters configuration: {best_comb}')\n",
    "    dev_pred = best_trainer.predict(tkn_dt['test'])\n",
    "    pred = np.argmax(dev_pred.predictions, axis=-1)\n",
    "    pred_score = np.max(torch.nn.functional.softmax(torch.tensor(dev_pred.predictions), dim=-1).numpy(), axis=-1)\n",
    "    i = 0\n",
    "    errors = {'FP': [], 'FN': []}\n",
    "    for pred_lab, true_lab in zip(pred, dev_pred.label_ids):\n",
    "        if pred_lab != true_lab:\n",
    "            if pred_lab > 1:\n",
    "                errors['FP'].append((\n",
    "                    tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(tkn_dt['test']['input_ids'][i])),\n",
    "                    pred_score[i], labels_to_sen[pred_lab], labels_to_sen[true_lab]))\n",
    "            else:\n",
    "                errors['FN'].append((tokenizer.convert_tokens_to_string(\n",
    "                    tokenizer.convert_ids_to_tokens(tkn_dt['test']['input_ids'][i])), pred_score[i],\n",
    "                                     labels_to_sen[pred_lab], labels_to_sen[true_lab]))\n",
    "        i += 1\n",
    "    with open(f'error_analysis_MD.tsv',\n",
    "              'w') as f:\n",
    "        f.write('sentence\\tpredicted_label\\ttrue_label\\tprobability\\n')\n",
    "        for k, vect in errors.items():\n",
    "            if k == 'FP':\n",
    "                for sen in vect:\n",
    "                    f.write(sen[0] + '\\t' + f'PRED_{sen[2].upper()}' + '\\t' + f'TRUE_{sen[3].upper()}' + '\\t' + str(\n",
    "                        sen[1]) + '\\n')\n",
    "                f.write('\\n')\n",
    "            else:\n",
    "                for sen in vect:\n",
    "                    f.write(sen[0] + '\\t' + f'PRED_{sen[2].upper()}' + '\\t' + f'TRUE_{sen[3].upper()}' + '\\t' + str(\n",
    "                        sen[1]) + '\\n')\n",
    "    test_pred = best_trainer.predict(tkn_dt['test'])\n",
    "    print(test_pred.metrics)\n",
    "\n",
    "    model_dir = f'runs/MD'\n",
    "    for d in os.listdir(model_dir):\n",
    "        # This removes the checkpoints (comment it if you want to keep them)\n",
    "        if 'checkpoint' in d:\n",
    "            shutil.rmtree(os.path.join(model_dir, d))\n",
    "    best_trainer.save_model(\n",
    "        output_dir=f'best_model/MD')\n",
    "else:\n",
    "    print(\"Precision is 0.0 change something in your model's configuration and retry.\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d11ca-ac15-43b2-acb4-7fb96a479831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
